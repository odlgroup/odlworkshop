{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for Part 3\n",
    "\n",
    "These small exercises are intended to build on the knowledge that you acquired in the [Learned Reconstruction](part3_learned_reconstruction) notebook. The exercises do not depend on each other. Feel free to pick those you like and do them in any order.\n",
    "\n",
    "We do not indend for all attendants to solve all of these during the course, but recommend that you at least read them.\n",
    "\n",
    "### Related exercises\n",
    "\n",
    "All of the exercises from [Part 2](part2_exercises.ipynb) can also be applied to inverse problems. Try them out here as well!\n",
    "\n",
    "### General note\n",
    "\n",
    "If you have trouble understanding the explanations, or if there is an error, please [let us know](https://github.com/odlgroup/odl/issues). These examples are meant to be understandable pretty much without prior knowledge, and we appreciate any feedback on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on performance\n",
    "\n",
    "If you are running the exercises on a shared machine (e.g. Radon) you may want to add the following lines to the start of your code which will pick a GPU that is not used by anyone else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install https://github.com/adler-j/adler/archive/master.zip\n",
    "import adler\n",
    "adler.util.gpu.setup_one_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1: Primal-Dual Reconstruction\n",
    "\n",
    "In the example code, we implemented a so called Learned Gradient scheme. This type of scheme only operates on the image, and not on the data. Another type of reconstruction scheme is [Learned Primal-Dual Reconstruction](https://arxiv.org/abs/1707.06474), in these schemes we iterate on both image and data. A very simple version would be given by\n",
    "\n",
    "$$\n",
    "x_0 = \\mathcal{T}^\\dagger(y)\n",
    "\\\\\n",
    "h_0 = y\n",
    "\\\\\n",
    "h_{i+1} = \\Gamma_{\\theta_i^d}(h_i, \\mathcal{T}(x_i), y) \\\\\n",
    "x_{i+1} = \\Lambda_{\\theta_i^p}(x_i, \\mathcal{T}^*(h_{i+1})) \\\\\n",
    "\\mathcal{T}_\\theta^\\dagger = x_I\n",
    "$$\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* Implement a learned primal-dual scheme. How do the results compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 2: Memory in learned iterative schemes\n",
    "\n",
    "In the learned gradient scheme in the examples, and in the learned primal-dual scheme above, the only connection between the iterates is $x_i \\in \\mathcal{X}$ (and $h_i \\in \\mathcal{Y}$).\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* What happens if we instead use $x_0 = [\\mathcal{T}^\\dagger(y), ..., \\mathcal{T}^\\dagger(y)]$. Do the results improve? What about doing the same for y?\n",
    "* In so called [DenseNets](https://arxiv.org/abs/1608.06993) (which are the current state of the art in image classification), we retain information from some of the previous iterates. For example, we could use\n",
    "$$\n",
    "h_{i+1} = \\Gamma_{\\theta_i^d}(h_i, h_{i-1}, ..., h_0, \\mathcal{T}(x_i), y) \\\\\n",
    "$$\n",
    "How does this change the results? Is it better to only retain a few iterates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Variational reconstruction\n",
    "\n",
    "Interestingly, the TV-regularized reconstruction out-performs the fully learned reconstruction, even if it does worse than the other learned methods. TV-regularization is not even the most effective method known.\n",
    "\n",
    "### Tasks\n",
    "* Implement a huber-regularized reconstruction (see e.g. [odl/examples/solvers/lbfgs_tomography_tv.tv](https://github.com/odlgroup/odl/blob/master/examples/solvers/lbfgs_tomography_tv.py)). How does it compare to the TV regularized reconstructin? What are the best parameter choices? What about run-time?\n",
    "* [Advanced] Implement Total Generalized Variation (TGV) regularized reconstruction, e.g.\n",
    "$$\n",
    "min_x ||\\mathcal{T}x - y||_2^2 + \\alpha TGV_2(x)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "TGV_2(x) = min_y ||\\nabla x - y||_1 + \\beta ||\\nabla y||_1\n",
    "$$\n",
    "see e.g. [odl/examples/solvers/pdhg_tomography_tgv.tv](https://github.com/odlgroup/odl/blob/master/examples/solvers/pdhg_tomography_tgv.py) for an example implementation and further documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Filtered Back-Projection\n",
    "\n",
    "In the notebook, we did simple FBP with a ramp filter. However the function [`odl.tomo.fbp_op`](https://odlgroup.github.io/odl/generated/odl.tomo.analytic.filtered_back_projection.fbp_op.html) also allows adding some extra filtering.\n",
    "\n",
    "### Tasks\n",
    "* Try setting `filter_type` to any of `'Ram-Lak'`, `'Shepp-Logan'`, `'Cosine'`, `'Hamming'` or `'Hann'`, how does the result change?\n",
    "* Try setting the filter parameter `frequency_scaling` to some other value. What happens with `frequency_scaling=0.1`? \n",
    "* How does using a different filter impact the result of the \"FBP + Learned denoiser\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
